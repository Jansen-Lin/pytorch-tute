{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# #################################################################################################\n",
      "#  Full ANN Code Along - Regression Part One(1) - Feature Engineering\n",
      "# #################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\"\"\n",
    "# #################################################################################################\n",
    "#  Full ANN Code Along - Regression Part One(1) - Feature Engineering\n",
    "# #################################################################################################\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
      "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
      "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
      "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
      "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
      "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
      "0        40.730521         -73.975499         40.744746                1  \n",
      "1        40.740558         -73.974232         40.744114                1  \n",
      "2        40.751118         -73.960064         40.766235                2  \n",
      "3        40.756422         -73.971205         40.748192                1  \n",
      "4        40.734202         -73.905956         40.743115                1  \n",
      "count    120000.000000\n",
      "mean         10.040326\n",
      "std           7.500134\n",
      "min           2.500000\n",
      "25%           5.700000\n",
      "50%           7.700000\n",
      "75%          11.300000\n",
      "max          49.900000\n",
      "Name: fare_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../../notebooks/Data/NYCTaxiFares.csv')\n",
    "print(df.head())\n",
    "print(df['fare_amount'].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [],
   "source": [
    "def haversine_distance(df, src_lat, src_long, tar_lat, tar_long):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "\n",
    "    phi1 = np.radians(df[src_lat])\n",
    "    phi2 = np.radians(df[tar_lat])\n",
    "\n",
    "    delta_phi = phi2 - phi1\n",
    "    delta_lambda = np.radians(df[tar_long] - df[src_long])\n",
    "\n",
    "    a = np.sin(delta_phi / 2) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    d = (r * c)  # in kilometers\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.126312\n",
      "1    1.392307\n",
      "2    3.326763\n",
      "3    1.864129\n",
      "4    7.231321\n",
      "Name: dist_km, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   pickup_datetime    120000 non-null  object \n",
      " 1   fare_amount        120000 non-null  float64\n",
      " 2   fare_class         120000 non-null  int64  \n",
      " 3   pickup_longitude   120000 non-null  float64\n",
      " 4   pickup_latitude    120000 non-null  float64\n",
      " 5   dropoff_longitude  120000 non-null  float64\n",
      " 6   dropoff_latitude   120000 non-null  float64\n",
      " 7   passenger_count    120000 non-null  int64  \n",
      " 8   dist_km            120000 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 8.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING - Taking a existing features already have, create new more useful features\n",
    "# than original features.\n",
    "\n",
    "# Engineering distance between two points with co-ordinates.\n",
    "df['dist_km'] = haversine_distance(df, 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "                                   'dropoff_longitude')\n",
    "print(df['dist_km'].head())\n",
    "\n",
    "print(df.info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype              \n",
      "---  ------             --------------   -----              \n",
      " 0   pickup_datetime    120000 non-null  datetime64[ns, UTC]\n",
      " 1   fare_amount        120000 non-null  float64            \n",
      " 2   fare_class         120000 non-null  int64              \n",
      " 3   pickup_longitude   120000 non-null  float64            \n",
      " 4   pickup_latitude    120000 non-null  float64            \n",
      " 5   dropoff_longitude  120000 non-null  float64            \n",
      " 6   dropoff_latitude   120000 non-null  float64            \n",
      " 7   passenger_count    120000 non-null  int64              \n",
      " 8   dist_km            120000 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(6), int64(2)\n",
      "memory usage: 8.2 MB\n",
      "None\n",
      "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
      "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
      "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
      "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
      "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
      "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
      "0        40.730521         -73.975499         40.744746                1   \n",
      "1        40.740558         -73.974232         40.744114                1   \n",
      "2        40.751118         -73.960064         40.766235                2   \n",
      "3        40.756422         -73.971205         40.748192                1   \n",
      "4        40.734202         -73.905956         40.743115                1   \n",
      "\n",
      "    dist_km  \n",
      "0  2.126312  \n",
      "1  1.392307  \n",
      "2  3.326763  \n",
      "3  1.864129  \n",
      "4  7.231321  \n"
     ]
    }
   ],
   "source": [
    "# Engineering datetime object(string) to be DateTime object.\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "print(df.info())\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-04-19 08:17:56+00:00\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "my_time = df['pickup_datetime'][0]\n",
    "print(my_time)\n",
    "print(my_time.hour)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
      "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
      "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
      "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
      "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
      "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
      "0        40.730521         -73.975499         40.744746                1   \n",
      "1        40.740558         -73.974232         40.744114                1   \n",
      "2        40.751118         -73.960064         40.766235                2   \n",
      "3        40.756422         -73.971205         40.748192                1   \n",
      "4        40.734202         -73.905956         40.743115                1   \n",
      "\n",
      "    dist_km                   EDTDate  Hour AMorPM Weekday  \n",
      "0  2.126312 2010-04-19 04:17:56-04:00     4     am     Mon  \n",
      "1  1.392307 2010-04-17 11:43:53-04:00    11     am     Sat  \n",
      "2  3.326763 2010-04-17 07:23:26-04:00     7     am     Sat  \n",
      "3  1.864129 2010-04-11 17:25:03-04:00    17     pm     Sun  \n",
      "4  7.231321 2010-04-16 22:19:01-04:00    22     pm     Fri  \n"
     ]
    }
   ],
   "source": [
    "df['EDTDate'] = df['pickup_datetime'].dt.tz_convert('US/Eastern')\n",
    "df['Hour'] = df['EDTDate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour'] >= 12, 'pm', 'am')\n",
    "df['Weekday'] = df['EDTDate'].dt.strftime('%a')\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# #################################################################################################\n",
      "#  Full ANN Code Along - Regression Part Two(2) (Categorical and Continuous Features)\n",
      "# #################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "# #################################################################################################\n",
    "#  Full ANN Code Along - Regression Part Two(2) (Categorical and Continuous Features)\n",
    "# #################################################################################################\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "categorical_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "continuous_cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                   'dropoff_latitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_amount']     # Hence regression problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [],
   "source": [
    "# Change the categorical columns's data type('dtype') to 'category' type, so neural network can understand\n",
    "# assigning a number.\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [
    {
     "data": {
      "text/plain": "0     4\n1    11\n2     7\n3    17\n4    22\nName: Hour, dtype: category\nCategories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [
    {
     "data": {
      "text/plain": "0    am\n1    am\n2    am\n3    pm\n4    pm\nName: AMorPM, dtype: category\nCategories (2, object): [am, pm]"
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [
    {
     "data": {
      "text/plain": "0    Mon\n1    Sat\n2    Sat\n3    Sun\n4    Fri\nName: Weekday, dtype: category\nCategories (7, object): [Fri, Mon, Sat, Sun, Thu, Tue, Wed]"
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype                     \n",
      "---  ------             --------------   -----                     \n",
      " 0   pickup_datetime    120000 non-null  datetime64[ns, UTC]       \n",
      " 1   fare_amount        120000 non-null  float64                   \n",
      " 2   fare_class         120000 non-null  int64                     \n",
      " 3   pickup_longitude   120000 non-null  float64                   \n",
      " 4   pickup_latitude    120000 non-null  float64                   \n",
      " 5   dropoff_longitude  120000 non-null  float64                   \n",
      " 6   dropoff_latitude   120000 non-null  float64                   \n",
      " 7   passenger_count    120000 non-null  int64                     \n",
      " 8   dist_km            120000 non-null  float64                   \n",
      " 9   EDTDate            120000 non-null  datetime64[ns, US/Eastern]\n",
      " 10  Hour               120000 non-null  category                  \n",
      " 11  AMorPM             120000 non-null  category                  \n",
      " 12  Weekday            120000 non-null  category                  \n",
      "dtypes: category(3), datetime64[ns, US/Eastern](1), datetime64[ns, UTC](1), float64(6), int64(2)\n",
      "memory usage: 9.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['am', 'pm'], dtype='object')\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         1\n",
      "4         1\n",
      "         ..\n",
      "119995    0\n",
      "119996    0\n",
      "119997    1\n",
      "119998    0\n",
      "119999    1\n",
      "Length: 120000, dtype: int8\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# We can access 'category' type object details using '.cat' as in '.dt' for 'DateTime' objects.\n",
    "print(df['AMorPM'].cat.categories)\n",
    "print(df['AMorPM'].cat.codes)\n",
    "\n",
    "vals = df['AMorPM'].cat.codes.values\n",
    "print(type(vals))\n",
    "print(vals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  1]\n",
      " [11  0  2]\n",
      " [ 7  0  2]\n",
      " ...\n",
      " [14  1  3]\n",
      " [ 4  0  5]\n",
      " [12  1  2]]\n"
     ]
    }
   ],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkd = df['Weekday'].cat.codes.values\n",
    "\n",
    "cat = np.stack([hr, ampm, wkd], axis=1) # Join each array as a column thus, axis=1.\n",
    "print(cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  1]\n",
      " [11  0  2]\n",
      " [ 7  0  2]\n",
      " ...\n",
      " [14  1  3]\n",
      " [ 4  0  5]\n",
      " [12  1  2]]\n",
      "[[ 4  0  1]\n",
      " [11  0  2]\n",
      " [ 7  0  2]\n",
      " ...\n",
      " [14  1  3]\n",
      " [ 4  0  5]\n",
      " [12  1  2]]\n"
     ]
    }
   ],
   "source": [
    "# Use 'list' comprehension to derive values and stack them up to single numpy array.\n",
    "cat = np.stack([df[col].cat.codes.values for col in categorical_cols], axis=1)\n",
    "print(cat)\n",
    "\n",
    "# OR skip change data type 'for loop' and embed it into the list comprehension as well.\n",
    "\n",
    "cat = np.stack([df[col].astype('category').cat.codes.values for col in categorical_cols], axis=1)\n",
    "print(cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  0,  1],\n",
      "        [11,  0,  2],\n",
      "        [ 7,  0,  2],\n",
      "        ...,\n",
      "        [14,  1,  3],\n",
      "        [ 4,  0,  5],\n",
      "        [12,  1,  2]])\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy array to 'tensor'.\n",
    "cat = torch.tensor(cat, dtype=torch.int64)\n",
    "print(cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-73.992365    40.730521   -73.975499    40.744746     1.\n",
      "    2.12631159]\n",
      " [-73.990078    40.740558   -73.974232    40.744114     1.\n",
      "    1.39230687]\n",
      " [-73.994149    40.751118   -73.960064    40.766235     2.\n",
      "    3.32676344]\n",
      " ...\n",
      " [-73.988574    40.749772   -74.011541    40.707799     3.\n",
      "    5.05252282]\n",
      " [-74.004449    40.724529   -73.992697    40.730765     1.\n",
      "    1.20892296]\n",
      " [-73.955415    40.77192    -73.967623    40.763015     3.\n",
      "    1.42739869]]\n",
      "tensor([[-73.9924,  40.7305, -73.9755,  40.7447,   1.0000,   2.1263],\n",
      "        [-73.9901,  40.7406, -73.9742,  40.7441,   1.0000,   1.3923],\n",
      "        [-73.9941,  40.7511, -73.9601,  40.7662,   2.0000,   3.3268],\n",
      "        ...,\n",
      "        [-73.9886,  40.7498, -74.0115,  40.7078,   3.0000,   5.0525],\n",
      "        [-74.0044,  40.7245, -73.9927,  40.7308,   1.0000,   1.2089],\n",
      "        [-73.9554,  40.7719, -73.9676,  40.7630,   3.0000,   1.4274]])\n"
     ]
    }
   ],
   "source": [
    "# Continuous columns - Simply map them into a numpy since they are already numerical values and neurons basicaly\n",
    "# understand them.\n",
    "\n",
    "cont = np.stack([df[col].values for col in continuous_cols], axis=1)\n",
    "print(cont)\n",
    "\n",
    "# To a 'tensor'.\n",
    "cont = torch.tensor(cont, dtype=torch.float)\n",
    "print(cont)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.5000],\n",
      "        [ 6.9000],\n",
      "        [10.1000],\n",
      "        ...,\n",
      "        [12.5000],\n",
      "        [ 4.9000],\n",
      "        [ 5.3000]])\n"
     ]
    }
   ],
   "source": [
    "# CREATE the labels using 'fare_amount' columns, hence need to predict 'fare_amount' base on categorical and continuous\n",
    "# columns values after training.\n",
    "y = torch.tensor(df['fare_amount'].values, dtype=torch.float32).reshape(-1, 1)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120000, 3])\n",
      "torch.Size([120000, 6])\n",
      "torch.Size([120000, 1])\n"
     ]
    }
   ],
   "source": [
    "# After all the data prepared.\n",
    "print(cat.shape)\n",
    "print(cont.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 2, 7]\n",
      "[(24, 12), (2, 1), (7, 4)]\n"
     ]
    }
   ],
   "source": [
    "# #################################################################################################\n",
    "# SET EMBEDDING Sizes\n",
    "# #################################################################################################\n",
    "# 1. Step - Take category sizes.\n",
    "cat_szs = [len(df[col].cat.categories) for col in categorical_cols]\n",
    "print(cat_szs)\n",
    "\n",
    "# 2. Step - Take embedded sizes.\n",
    "embedding_szs = [(szs, min(50, (szs + 1) // 2)) for szs in cat_szs]\n",
    "print(embedding_szs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# ##############################################################################################################\n",
      "#  Full ANN Code Along - Regression Part Three(3) (Tabular Model - Embedding, Normalization, Dropout functions)\n",
      "# ##############################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "# ##############################################################################################################\n",
    "#  Full ANN Code Along - Regression Part Three(3) (Tabular Model - Embedding, Normalization, Dropout functions)\n",
    "# ##############################################################################################################\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  0,  1],\n",
      "        [11,  0,  2],\n",
      "        [ 7,  0,  2],\n",
      "        [17,  1,  3]])\n",
      "ModuleList(\n",
      "  (0): Embedding(24, 12)\n",
      "  (1): Embedding(2, 1)\n",
      "  (2): Embedding(7, 4)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Embedding for categorical data.\n",
    "cats_part = cat[:4]\n",
    "print(cats_part)\n",
    "\n",
    "self_embeds = nn.ModuleList([nn.Embedding(vocab_szs, vector_szs) for vocab_szs, vector_szs in embedding_szs])\n",
    "print(self_embeds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.4328, -0.7196, -1.2238, -0.3575, -0.9226, -2.0296,  0.1382,  0.7235,\n",
      "          0.7775, -0.3138, -2.4676,  1.1926],\n",
      "        [ 0.4694,  1.2791,  0.4876, -0.2494, -0.1783, -2.7201,  1.0955,  2.4367,\n",
      "          0.0406,  1.4228,  0.6940,  1.7791],\n",
      "        [ 0.4361,  0.0332,  0.5071, -0.5537,  0.1664,  0.6675, -0.0738, -1.1633,\n",
      "          1.2410, -0.8298, -0.8674, -0.5670],\n",
      "        [ 1.1491,  1.1070,  2.2900, -2.5212,  0.1286, -0.6873,  1.2923,  0.2201,\n",
      "         -0.7505, -0.4856, -0.0977,  1.5486]], grad_fn=<EmbeddingBackward>), tensor([[0.0740],\n",
      "        [0.0740],\n",
      "        [0.0740],\n",
      "        [0.1248]], grad_fn=<EmbeddingBackward>), tensor([[ 0.4777,  0.7462,  3.0095,  2.0934],\n",
      "        [ 0.2008, -0.3046, -1.4075, -0.6853],\n",
      "        [ 0.2008, -0.3046, -1.4075, -0.6853],\n",
      "        [-1.0269, -0.1672, -0.6329, -1.7203]], grad_fn=<EmbeddingBackward>)]\n"
     ]
    }
   ],
   "source": [
    "# FORWARD METHOD (cats)\n",
    "embeddings = []\n",
    "for i, e in enumerate(self_embeds):\n",
    "    embeddings.append(e(cats_part[:, i]))\n",
    "\n",
    "print(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4328, -0.7196, -1.2238, -0.3575, -0.9226, -2.0296,  0.1382,  0.7235,\n",
      "          0.7775, -0.3138, -2.4676,  1.1926,  0.0740,  0.4777,  0.7462,  3.0095,\n",
      "          2.0934],\n",
      "        [ 0.4694,  1.2791,  0.4876, -0.2494, -0.1783, -2.7201,  1.0955,  2.4367,\n",
      "          0.0406,  1.4228,  0.6940,  1.7791,  0.0740,  0.2008, -0.3046, -1.4075,\n",
      "         -0.6853],\n",
      "        [ 0.4361,  0.0332,  0.5071, -0.5537,  0.1664,  0.6675, -0.0738, -1.1633,\n",
      "          1.2410, -0.8298, -0.8674, -0.5670,  0.0740,  0.2008, -0.3046, -1.4075,\n",
      "         -0.6853],\n",
      "        [ 1.1491,  1.1070,  2.2900, -2.5212,  0.1286, -0.6873,  1.2923,  0.2201,\n",
      "         -0.7505, -0.4856, -0.0977,  1.5486,  0.1248, -1.0269, -0.1672, -0.6329,\n",
      "         -1.7203]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate embeddings together.\n",
    "z = torch.cat(embeddings, 1)\n",
    "print(z)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000, -0.0000, -2.0396, -0.0000, -0.0000, -3.3826,  0.2303,  1.2058,\n",
      "          1.2959, -0.0000, -0.0000,  0.0000,  0.1234,  0.0000,  1.2436,  0.0000,\n",
      "          3.4890],\n",
      "        [ 0.0000,  2.1318,  0.8127, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  2.3713,  1.1566,  0.0000,  0.1234,  0.3346, -0.0000, -0.0000,\n",
      "         -1.1421],\n",
      "        [ 0.0000,  0.0553,  0.8452, -0.0000,  0.0000,  0.0000, -0.1230, -1.9388,\n",
      "          2.0683, -1.3830, -0.0000, -0.9450,  0.1234,  0.3346, -0.0000, -2.3459,\n",
      "         -1.1421],\n",
      "        [ 0.0000,  1.8451,  3.8166, -0.0000,  0.0000, -1.1454,  2.1539,  0.0000,\n",
      "         -0.0000, -0.8093, -0.1629,  2.5811,  0.2080, -0.0000, -0.2787, -1.0548,\n",
      "         -2.8672]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Dropout some values from dense-vector to avoid over-fitting.\n",
    "self_embed_dropout = nn.Dropout(p=0.4)\n",
    "z = self_embed_dropout(z)\n",
    "\n",
    "print(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "outputs": [],
   "source": [
    "# Build the 'TabularModel' class.\n",
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_continuous_f, output_size, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(vocab_szs, vector_szs) for vocab_szs, vector_szs in embedding_size])\n",
    "        self.batch_norm = nn.BatchNorm1d(num_continuous_f)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        num_embeds = sum([vector_szs for vocab_szs, vector_szs in embedding_size])\n",
    "        input_size = num_embeds + num_continuous_f\n",
    "\n",
    "        layer_list = []\n",
    "        for l in layers:\n",
    "            layer_list.append(nn.Linear(input_size, l))\n",
    "            layer_list.append(nn.ReLU(inplace=True))\n",
    "            layer_list.append(nn.BatchNorm1d(l))\n",
    "            layer_list.append(nn.Dropout(p))\n",
    "            input_size = l\n",
    "\n",
    "        layer_list.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layer = nn.Sequential(*layer_list)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        _embeddings = []\n",
    "        for n, emb in enumerate(self.embeddings):\n",
    "            _embeddings.append(emb(x_cat[:, n]))\n",
    "\n",
    "        x = torch.cat(_embeddings, 1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x_cont = self.batch_norm(x_cont)\n",
    "\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "\n",
    "        return self.layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): Linear(in_features=20, out_features=10, bias=True)\n",
      ")\n",
      "tensor([ 0.4729,  1.4988,  0.4074,  2.4774, -1.3765, -0.8307, -2.7751, -3.5074,\n",
      "         0.2735, -0.0444], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# What does 'nn.Sequential' do.\n",
    "s = nn.Sequential(nn.Linear(10, 20), nn.Linear(20, 10))\n",
    "print(s)\n",
    "\n",
    "input = torch.linspace(0, 10, 10)\n",
    "output = s(input)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 12), (2, 1), (7, 4)]\n",
      "TabularModel(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(24, 12)\n",
      "    (1): Embedding(2, 1)\n",
      "    (2): Embedding(7, 4)\n",
      "  )\n",
      "  (batch_norm): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(33)\n",
    "\n",
    "# embed_size = [(size, min(50, (size + 1) // 2)) for size in [len(df[col].cat.categories) for col in categorical_cols]]\n",
    "print(embedding_szs)\n",
    "\n",
    "model = TabularModel(embedding_szs, cont.shape[1], 1, [200, 100], p=0.4)\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "48000\n",
      "48000\n",
      "12000\n",
      "12000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()    # np.sqrt(MSE) -> Root Mean Squared Error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "batch_size = 60000\n",
    "test_size = int(batch_size * 0.2)\n",
    "\n",
    "# DATA SHUFFLED ALREADY.\n",
    "cat_train = cat[:batch_size - test_size]\n",
    "cat_test = cat[batch_size - test_size:batch_size]\n",
    "cont_train = cont[:batch_size - test_size]\n",
    "cont_test = cont[batch_size - test_size:batch_size]\n",
    "\n",
    "y_train = y[:batch_size - test_size]\n",
    "y_test = y[batch_size - test_size:batch_size]\n",
    "\n",
    "print(len(cat_train))\n",
    "print(len(cont_train))\n",
    "print(len(y_train))\n",
    "print(len(cat_test))\n",
    "print(len(cont_test))\n",
    "print(len(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 -> loss: 11.779982566833496\n",
      "epoch 11 -> loss: 9.593120574951172\n",
      "epoch 21 -> loss: 7.657689094543457\n",
      "epoch 31 -> loss: 4.390988826751709\n",
      "epoch 41 -> loss: 4.146971702575684\n",
      "epoch 51 -> loss: 3.578580141067505\n",
      "epoch 61 -> loss: 3.4814577102661133\n",
      "epoch 71 -> loss: 3.4180562496185303\n",
      "epoch 81 -> loss: 3.3725616931915283\n",
      "epoch 91 -> loss: 3.3421807289123535\n",
      "epoch 101 -> loss: 3.3276047706604004\n",
      "epoch 111 -> loss: 3.2868897914886475\n",
      "epoch 121 -> loss: 3.2872910499572754\n",
      "epoch 131 -> loss: 3.270890474319458\n",
      "epoch 141 -> loss: 3.2557871341705322\n",
      "epoch 151 -> loss: 3.2567243576049805\n",
      "epoch 161 -> loss: 3.245924949645996\n",
      "epoch 171 -> loss: 3.2447922229766846\n",
      "epoch 181 -> loss: 3.2497453689575195\n",
      "epoch 191 -> loss: 3.2212650775909424\n",
      "epoch 201 -> loss: 3.2076141834259033\n",
      "epoch 211 -> loss: 3.2244269847869873\n",
      "epoch 221 -> loss: 3.2053728103637695\n",
      "epoch 231 -> loss: 3.203829050064087\n",
      "epoch 241 -> loss: 3.200155735015869\n",
      "epoch 251 -> loss: 3.1930699348449707\n",
      "epoch 261 -> loss: 3.19673752784729\n",
      "epoch 271 -> loss: 3.1885178089141846\n",
      "epoch 281 -> loss: 3.1777210235595703\n",
      "epoch 291 -> loss: 3.1669514179229736\n",
      "Training took 14.246909407774607 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    y_pred = model.forward(cat_train, cont_train)\n",
    "    # Calculate Root Mean Square Error hence dealing with price units, otherwise loss values\n",
    "    # (in this case 'fare_amount') would be squared.\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train))  # Hence the dealing with prices.\n",
    "\n",
    "    losses.append(loss)\n",
    "\n",
    "    if i % 10 == 1: # Print the very first one as well.\n",
    "        print(f'\\repoch {i} -> loss: {loss}')\n",
    "\n",
    "    # Back propagate.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "duration = time.time() - start_time # In seconds.\n",
    "print(f'Training took {duration / 60} minutes')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'full_ann_state.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'RMSE Loss')"
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE Loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0754)\n",
      "0.) PREDICTED:     2.90, ACTUAL:     2.90, DIFF: 0.0009059906005859375 \n",
      "1.) PREDICTED:    20.10, ACTUAL:     5.70, DIFF: 14.40075969696045 \n",
      "2.) PREDICTED:     6.26, ACTUAL:     7.70, DIFF: 1.4407873153686523 \n",
      "3.) PREDICTED:    13.12, ACTUAL:    12.50, DIFF: 0.6246471405029297 \n",
      "4.) PREDICTED:     4.41, ACTUAL:     4.10, DIFF: 0.31119775772094727 \n",
      "5.) PREDICTED:     5.30, ACTUAL:     5.30, DIFF: 0.0049896240234375 \n",
      "6.) PREDICTED:     4.59, ACTUAL:     3.70, DIFF: 0.8899905681610107 \n",
      "7.) PREDICTED:    16.10, ACTUAL:    14.50, DIFF: 1.6042251586914062 \n",
      "8.) PREDICTED:     4.75, ACTUAL:     5.70, DIFF: 0.952178955078125 \n",
      "9.) PREDICTED:     9.25, ACTUAL:    10.10, DIFF: 0.8510065078735352 \n"
     ]
    }
   ],
   "source": [
    "# 1. Check the loss immediate loss values.\n",
    "with torch.no_grad():\n",
    "\n",
    "    y_pred = model.forward(cat_test, cont_test)\n",
    "\n",
    "    loss = torch.sqrt(criterion(y_pred, y_test))\n",
    "\n",
    "    print(loss) # tensor(3.1052) - pretty much good value. No over-fitting.\n",
    "\n",
    "# 2. Check with the entire test result set.\n",
    "for i in range(10):\n",
    "    diff = np.abs(y_pred[i].item() - y_test[i].item())\n",
    "    print(f'{i}.) PREDICTED: {y_pred[i].item():8.2f}, ACTUAL: {y_test[i].item():8.2f}, DIFF: {diff} ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a503b19",
   "language": "python",
   "display_name": "PyCharm (pytorch-tute)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}