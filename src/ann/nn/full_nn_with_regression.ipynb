{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# #################################################################################################\n",
      "#  Full ANN Code Along - Regression Part One(1) - Feature Engineering\n",
      "# #################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\"\"\n",
    "# #################################################################################################\n",
    "#  Full ANN Code Along - Regression Part One(1) - Feature Engineering\n",
    "# #################################################################################################\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
      "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
      "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
      "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
      "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
      "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
      "0        40.730521         -73.975499         40.744746                1  \n",
      "1        40.740558         -73.974232         40.744114                1  \n",
      "2        40.751118         -73.960064         40.766235                2  \n",
      "3        40.756422         -73.971205         40.748192                1  \n",
      "4        40.734202         -73.905956         40.743115                1  \n",
      "count    120000.000000\n",
      "mean         10.040326\n",
      "std           7.500134\n",
      "min           2.500000\n",
      "25%           5.700000\n",
      "50%           7.700000\n",
      "75%          11.300000\n",
      "max          49.900000\n",
      "Name: fare_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../../notebooks/Data/NYCTaxiFares.csv')\n",
    "print(df.head())\n",
    "print(df['fare_amount'].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def haversine_distance(df, src_lat, src_long, tar_lat, tar_long):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "\n",
    "    phi1 = np.radians(df[src_lat])\n",
    "    phi2 = np.radians(df[tar_lat])\n",
    "\n",
    "    delta_phi = phi2 - phi1\n",
    "    delta_lambda = np.radians(df[tar_long] - df[src_long])\n",
    "\n",
    "    a = np.sin(delta_phi / 2) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    d = (r * c)  # in kilometers\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.126312\n",
      "1    1.392307\n",
      "2    3.326763\n",
      "3    1.864129\n",
      "4    7.231321\n",
      "Name: dist_km, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   pickup_datetime    120000 non-null  object \n",
      " 1   fare_amount        120000 non-null  float64\n",
      " 2   fare_class         120000 non-null  int64  \n",
      " 3   pickup_longitude   120000 non-null  float64\n",
      " 4   pickup_latitude    120000 non-null  float64\n",
      " 5   dropoff_longitude  120000 non-null  float64\n",
      " 6   dropoff_latitude   120000 non-null  float64\n",
      " 7   passenger_count    120000 non-null  int64  \n",
      " 8   dist_km            120000 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 8.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING - Taking a existing features already have, create new more useful features\n",
    "# than original features.\n",
    "\n",
    "# Engineering distance between two points with co-ordinates.\n",
    "df['dist_km'] = haversine_distance(df, 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "                                   'dropoff_longitude')\n",
    "print(df['dist_km'].head())\n",
    "\n",
    "print(df.info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype              \n",
      "---  ------             --------------   -----              \n",
      " 0   pickup_datetime    120000 non-null  datetime64[ns, UTC]\n",
      " 1   fare_amount        120000 non-null  float64            \n",
      " 2   fare_class         120000 non-null  int64              \n",
      " 3   pickup_longitude   120000 non-null  float64            \n",
      " 4   pickup_latitude    120000 non-null  float64            \n",
      " 5   dropoff_longitude  120000 non-null  float64            \n",
      " 6   dropoff_latitude   120000 non-null  float64            \n",
      " 7   passenger_count    120000 non-null  int64              \n",
      " 8   dist_km            120000 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(6), int64(2)\n",
      "memory usage: 8.2 MB\n",
      "None\n",
      "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
      "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
      "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
      "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
      "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
      "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
      "0        40.730521         -73.975499         40.744746                1   \n",
      "1        40.740558         -73.974232         40.744114                1   \n",
      "2        40.751118         -73.960064         40.766235                2   \n",
      "3        40.756422         -73.971205         40.748192                1   \n",
      "4        40.734202         -73.905956         40.743115                1   \n",
      "\n",
      "    dist_km  \n",
      "0  2.126312  \n",
      "1  1.392307  \n",
      "2  3.326763  \n",
      "3  1.864129  \n",
      "4  7.231321  \n"
     ]
    }
   ],
   "source": [
    "# Engineering datetime object(string) to be DateTime object.\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "print(df.info())\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-04-19 08:17:56+00:00\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "my_time = df['pickup_datetime'][0]\n",
    "print(my_time)\n",
    "print(my_time.hour)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
      "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
      "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
      "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
      "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
      "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
      "0        40.730521         -73.975499         40.744746                1   \n",
      "1        40.740558         -73.974232         40.744114                1   \n",
      "2        40.751118         -73.960064         40.766235                2   \n",
      "3        40.756422         -73.971205         40.748192                1   \n",
      "4        40.734202         -73.905956         40.743115                1   \n",
      "\n",
      "    dist_km                   EDTDate  Hour AMorPM Weekday  \n",
      "0  2.126312 2010-04-19 04:17:56-04:00     4     am     Mon  \n",
      "1  1.392307 2010-04-17 11:43:53-04:00    11     am     Sat  \n",
      "2  3.326763 2010-04-17 07:23:26-04:00     7     am     Sat  \n",
      "3  1.864129 2010-04-11 17:25:03-04:00    17     pm     Sun  \n",
      "4  7.231321 2010-04-16 22:19:01-04:00    22     pm     Fri  \n"
     ]
    }
   ],
   "source": [
    "df['EDTDate'] = df['pickup_datetime'].dt.tz_convert('US/Eastern')\n",
    "df['Hour'] = df['EDTDate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour'] >= 12, 'pm', 'am')\n",
    "df['Weekday'] = df['EDTDate'].dt.strftime('%a')\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# #################################################################################################\n",
      "#  Full ANN Code Along - Regression Part Two(2) (Categorical and Continuous Features)\n",
      "# #################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "# #################################################################################################\n",
    "#  Full ANN Code Along - Regression Part Two(2) (Categorical and Continuous Features)\n",
    "# #################################################################################################\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "categorical_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "continuous_cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                   'dropoff_latitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_amount']     # Hence regression problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Change the categorical columns's data type('dtype') to 'category' type, so neural network can understand\n",
    "# assigning a number.\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0     4\n1    11\n2     7\n3    17\n4    22\nName: Hour, dtype: category\nCategories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0    am\n1    am\n2    am\n3    pm\n4    pm\nName: AMorPM, dtype: category\nCategories (2, object): [am, pm]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0    Mon\n1    Sat\n2    Sat\n3    Sun\n4    Fri\nName: Weekday, dtype: category\nCategories (7, object): [Fri, Mon, Sat, Sun, Thu, Tue, Wed]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype                     \n",
      "---  ------             --------------   -----                     \n",
      " 0   pickup_datetime    120000 non-null  datetime64[ns, UTC]       \n",
      " 1   fare_amount        120000 non-null  float64                   \n",
      " 2   fare_class         120000 non-null  int64                     \n",
      " 3   pickup_longitude   120000 non-null  float64                   \n",
      " 4   pickup_latitude    120000 non-null  float64                   \n",
      " 5   dropoff_longitude  120000 non-null  float64                   \n",
      " 6   dropoff_latitude   120000 non-null  float64                   \n",
      " 7   passenger_count    120000 non-null  int64                     \n",
      " 8   dist_km            120000 non-null  float64                   \n",
      " 9   EDTDate            120000 non-null  datetime64[ns, US/Eastern]\n",
      " 10  Hour               120000 non-null  category                  \n",
      " 11  AMorPM             120000 non-null  category                  \n",
      " 12  Weekday            120000 non-null  category                  \n",
      "dtypes: category(3), datetime64[ns, US/Eastern](1), datetime64[ns, UTC](1), float64(6), int64(2)\n",
      "memory usage: 9.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['am', 'pm'], dtype='object')\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         1\n",
      "4         1\n",
      "         ..\n",
      "119995    0\n",
      "119996    0\n",
      "119997    1\n",
      "119998    0\n",
      "119999    1\n",
      "Length: 120000, dtype: int8\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# We can access 'category' type object details using '.cat' as in '.dt' for 'DateTime' objects.\n",
    "print(df['AMorPM'].cat.categories)\n",
    "print(df['AMorPM'].cat.codes)\n",
    "\n",
    "vals = df['AMorPM'].cat.codes.values\n",
    "print(type(vals))\n",
    "print(vals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  1]\n",
      " [11  0  2]\n",
      " [ 7  0  2]\n",
      " ...\n",
      " [14  1  3]\n",
      " [ 4  0  5]\n",
      " [12  1  2]]\n"
     ]
    }
   ],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkd = df['Weekday'].cat.codes.values\n",
    "\n",
    "cat = np.stack([hr, ampm, wkd], axis=1) # Join each array as a column thus, axis=1.\n",
    "print(cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  1]\n",
      " [11  0  2]\n",
      " [ 7  0  2]\n",
      " ...\n",
      " [14  1  3]\n",
      " [ 4  0  5]\n",
      " [12  1  2]]\n",
      "[[ 4  0  1]\n",
      " [11  0  2]\n",
      " [ 7  0  2]\n",
      " ...\n",
      " [14  1  3]\n",
      " [ 4  0  5]\n",
      " [12  1  2]]\n"
     ]
    }
   ],
   "source": [
    "# Use 'list' comprehension to derive values and stack them up to single numpy array.\n",
    "cat = np.stack([df[col].cat.codes.values for col in categorical_cols], axis=1)\n",
    "print(cat)\n",
    "\n",
    "# OR skip change data type 'for loop' and embed it into the list comprehension as well.\n",
    "\n",
    "cat = np.stack([df[col].astype('category').cat.codes.values for col in categorical_cols], axis=1)\n",
    "print(cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  0,  1],\n",
      "        [11,  0,  2],\n",
      "        [ 7,  0,  2],\n",
      "        ...,\n",
      "        [14,  1,  3],\n",
      "        [ 4,  0,  5],\n",
      "        [12,  1,  2]])\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy array to 'tensor'.\n",
    "cat = torch.tensor(cat, dtype=torch.int64)\n",
    "print(cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-73.992365    40.730521   -73.975499    40.744746     1.\n",
      "    2.12631159]\n",
      " [-73.990078    40.740558   -73.974232    40.744114     1.\n",
      "    1.39230687]\n",
      " [-73.994149    40.751118   -73.960064    40.766235     2.\n",
      "    3.32676344]\n",
      " ...\n",
      " [-73.988574    40.749772   -74.011541    40.707799     3.\n",
      "    5.05252282]\n",
      " [-74.004449    40.724529   -73.992697    40.730765     1.\n",
      "    1.20892296]\n",
      " [-73.955415    40.77192    -73.967623    40.763015     3.\n",
      "    1.42739869]]\n",
      "tensor([[-73.9924,  40.7305, -73.9755,  40.7447,   1.0000,   2.1263],\n",
      "        [-73.9901,  40.7406, -73.9742,  40.7441,   1.0000,   1.3923],\n",
      "        [-73.9941,  40.7511, -73.9601,  40.7662,   2.0000,   3.3268],\n",
      "        ...,\n",
      "        [-73.9886,  40.7498, -74.0115,  40.7078,   3.0000,   5.0525],\n",
      "        [-74.0044,  40.7245, -73.9927,  40.7308,   1.0000,   1.2089],\n",
      "        [-73.9554,  40.7719, -73.9676,  40.7630,   3.0000,   1.4274]])\n"
     ]
    }
   ],
   "source": [
    "# Continuous columns - Simply map them into a numpy since they are already numerical values and neurons basicaly\n",
    "# understand them.\n",
    "\n",
    "cont = np.stack([df[col].values for col in continuous_cols], axis=1)\n",
    "print(cont)\n",
    "\n",
    "# To a 'tensor'.\n",
    "cont = torch.tensor(cont, dtype=torch.float)\n",
    "print(cont)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.5000],\n",
      "        [ 6.9000],\n",
      "        [10.1000],\n",
      "        ...,\n",
      "        [12.5000],\n",
      "        [ 4.9000],\n",
      "        [ 5.3000]])\n"
     ]
    }
   ],
   "source": [
    "# CREATE the labels using 'fare_amount' columns, hence need to predict 'fare_amount' base on categorical and continuous\n",
    "# columns values after training.\n",
    "y = torch.tensor(df['fare_amount'].values, dtype=torch.float32).reshape(-1, 1)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120000, 3])\n",
      "torch.Size([120000, 6])\n",
      "torch.Size([120000, 1])\n"
     ]
    }
   ],
   "source": [
    "# After all the data prepared.\n",
    "print(cat.shape)\n",
    "print(cont.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 2, 7]\n",
      "[(24, 12), (2, 1), (7, 4)]\n"
     ]
    }
   ],
   "source": [
    "# #################################################################################################\n",
    "# SET EMBEDDING Sizes\n",
    "# #################################################################################################\n",
    "# 1. Step - Take category sizes.\n",
    "cat_szs = [len(df[col].cat.categories) for col in categorical_cols]\n",
    "print(cat_szs)\n",
    "\n",
    "# 2. Step - Take embedded sizes.\n",
    "embedding_szs = [(szs, min(50, (szs + 1) // 2)) for szs in cat_szs]\n",
    "print(embedding_szs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# ##############################################################################################################\n",
      "#  Full ANN Code Along - Regression Part Three(3) (Tabular Model - Embedding, Normalization, Dropout functions)\n",
      "# ##############################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "# ##############################################################################################################\n",
    "#  Full ANN Code Along - Regression Part Three(3) (Tabular Model - Embedding, Normalization, Dropout functions)\n",
    "# ##############################################################################################################\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  0,  1],\n",
      "        [11,  0,  2],\n",
      "        [ 7,  0,  2],\n",
      "        [17,  1,  3]])\n",
      "ModuleList(\n",
      "  (0): Embedding(24, 12)\n",
      "  (1): Embedding(2, 1)\n",
      "  (2): Embedding(7, 4)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Embedding for categorical data.\n",
    "cats_part = cat[:4]\n",
    "print(cats_part)\n",
    "\n",
    "self_embeds = nn.ModuleList([nn.Embedding(vocab_szs, vector_szs) for vocab_szs, vector_szs in embedding_szs])\n",
    "print(self_embeds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# FORWARD METHOD (cats)\n",
    "embeddings = []\n",
    "for i, e in enumerate(self_embeds):\n",
    "    embeddings.append(e(cats_part[:, i]))\n",
    "\n",
    "print(len(embeddings[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 17])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate embeddings together.\n",
    "z = torch.cat(embeddings, 1)\n",
    "print(z.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7924, -1.5316,  0.5040,  0.0000, -1.8812, -0.0000,  0.0000,  0.0000,\n",
      "         -0.0000,  0.6651, -1.7901, -0.0000, -0.0000, -0.0000,  0.4195, -3.9756,\n",
      "         -0.0000],\n",
      "        [ 1.1120,  2.3520,  1.9108,  1.9899, -1.2272,  0.0000, -0.3299, -2.5737,\n",
      "          0.1654, -0.9220,  2.0288, -0.0569, -0.1717,  1.3861, -0.7307,  0.0000,\n",
      "         -0.3266],\n",
      "        [ 0.0000,  0.2085,  1.9706,  0.0000,  0.8714, -0.1165, -0.9618,  2.9078,\n",
      "          1.2018, -0.3691, -1.8237,  2.6186, -0.0000,  1.3861, -0.7307,  0.0000,\n",
      "         -0.0000],\n",
      "        [ 2.9508,  0.0000, -1.9123,  1.6128, -1.5949,  1.3373,  0.0000,  0.5136,\n",
      "          3.4139, -2.6294, -0.0000, -2.5356,  0.0000,  0.0000, -1.1570, -0.0000,\n",
      "          2.3726]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Dropout some values from dense-vector to avoid over-fitting.\n",
    "self_embed_dropout = nn.Dropout(p=0.4)\n",
    "z = self_embed_dropout(z)\n",
    "\n",
    "print(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Build the 'TabularModel' class.\n",
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_continuous_f, output_size, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(vocab_szs, vector_szs) for vocab_szs, vector_szs in embedding_size])\n",
    "        self.batch_norm = nn.BatchNorm1d(num_continuous_f)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        num_embeds = sum([vector_szs for vocab_szs, vector_szs in embedding_size])\n",
    "        input_size = num_embeds + num_continuous_f\n",
    "\n",
    "        layer_list = []\n",
    "        for l in layers:\n",
    "            layer_list.append(nn.Linear(input_size, l))\n",
    "            layer_list.append(nn.ReLU(inplace=True))\n",
    "            layer_list.append(nn.BatchNorm1d(l))\n",
    "            layer_list.append(nn.Dropout(p))\n",
    "            input_size = l\n",
    "\n",
    "        layer_list.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layer = nn.Sequential(*layer_list)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        _embeddings = []\n",
    "        for n, emb in enumerate(self.embeddings):\n",
    "            _embeddings.append(emb(x_cat[:, n]))\n",
    "\n",
    "        x = torch.cat(_embeddings, 1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x_cont = self.batch_norm(x_cont)\n",
    "\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "\n",
    "        return self.layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): Linear(in_features=20, out_features=10, bias=True)\n",
      ")\n",
      "tensor([ 0.1831,  0.7487, -3.3607,  0.5072,  0.3675,  0.7700,  0.3308, -2.0476,\n",
      "         2.0286, -0.5559], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# What does 'nn.Sequential' do.\n",
    "s = nn.Sequential(nn.Linear(10, 20), nn.Linear(20, 10))\n",
    "print(s)\n",
    "\n",
    "input = torch.linspace(0, 10, 10)\n",
    "output = s(input)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 12), (2, 1), (7, 4)]\n",
      "TabularModel(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(24, 12)\n",
      "    (1): Embedding(2, 1)\n",
      "    (2): Embedding(7, 4)\n",
      "  )\n",
      "  (batch_norm): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(33)\n",
    "\n",
    "# embed_size = [(size, min(50, (size + 1) // 2)) for size in [len(df[col].cat.categories) for col in categorical_cols]]\n",
    "print(embedding_szs)\n",
    "\n",
    "model = TabularModel(embedding_szs, cont.shape[1], 1, [200, 100], p=0.4)\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "48000\n",
      "48000\n",
      "12000\n",
      "12000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()    # np.sqrt(MSE) -> Root Mean Squared Error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "batch_size = 60000\n",
    "test_size = int(batch_size * 0.2)\n",
    "\n",
    "# DATA SHUFFLED ALREADY.\n",
    "cat_train = cat[:batch_size - test_size]\n",
    "cat_test = cat[batch_size - test_size:batch_size]\n",
    "cont_train = cont[:batch_size - test_size]\n",
    "cont_test = cont[batch_size - test_size:batch_size]\n",
    "\n",
    "y_train = y[:batch_size - test_size]\n",
    "y_test = y[batch_size - test_size:batch_size]\n",
    "\n",
    "print(len(cat_train))\n",
    "print(len(cont_train))\n",
    "print(len(y_train))\n",
    "print(len(cat_test))\n",
    "print(len(cont_test))\n",
    "print(len(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 -> loss: 11.779982566833496\n",
      "epoch 11 -> loss: 9.593120574951172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-32-21b7fc73fd94>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;31m# Back propagate.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pytorchdev\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    196\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[1;33m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    197\u001B[0m         \"\"\"\n\u001B[1;32m--> 198\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    199\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pytorchdev\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m     96\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 98\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m     99\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    100\u001B[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    y_pred = model.forward(cat_train, cont_train)\n",
    "    # Calculate Root Mean Square Error hence dealing with price units, otherwise loss values\n",
    "    # (in this case 'fare_amount') would be squared.\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train))  # Hence the dealing with prices.\n",
    "\n",
    "    losses.append(loss)\n",
    "\n",
    "    if i % 10 == 1: # Print the very first one as well.\n",
    "        print(f'\\repoch {i} -> loss: {loss}')\n",
    "\n",
    "    # Back propagate.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "duration = time.time() - start_time # In seconds.\n",
    "print(f'Training took {duration / 60} minutes')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'full_ann_state.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE Loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Check the loss immediate loss values.\n",
    "with torch.no_grad():\n",
    "\n",
    "    y_pred = model.forward(cat_test, cont_test)\n",
    "\n",
    "    loss = torch.sqrt(criterion(y_pred, y_test))\n",
    "\n",
    "    print(loss) # tensor(3.1052) - pretty much good value. No over-fitting.\n",
    "\n",
    "# 2. Check with the entire test result set.\n",
    "for i in range(10):\n",
    "    diff = np.abs(y_pred[i].item() - y_test[i].item())\n",
    "    print(f'{i}.) PREDICTED: {y_pred[i].item():8.2f}, ACTUAL: {y_test[i].item():8.2f}, DIFF: {diff} ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a503b19",
   "language": "python",
   "display_name": "PyCharm (pytorch-tute)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}